
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>17. Model learning strategies &#8212; Applied Machine Learning, 2021</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Learning_model_parameters';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="16. Artificial Neural Networks (ANN)" href="NeuralNetworks.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="practicalities.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/ApplesAndOranges.png" class="logo__image only-light" alt="Applied Machine Learning, 2021 - Home"/>
    <script>document.write(`<img src="_static/ApplesAndOranges.png" class="logo__image only-dark" alt="Applied Machine Learning, 2021 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="practicalities.html">
                    About the course
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Modeling.html">2. Modeling</a></li>
<li class="toctree-l1"><a class="reference internal" href="ReadingAndPlotting.html">3. Reading and plotting</a></li>
<li class="toctree-l1"><a class="reference internal" href="Preprocessing_and_feature_extraction.html">4. Preprocessing and feature extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="Subspace_Projections.html">5. Dimensionality reduction by Subspace projections</a></li>
<li class="toctree-l1"><a class="reference internal" href="Clustering.html">6. Unsupervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="SupervisedMachineLearningTerminology.html">7. Training process</a></li>




<li class="toctree-l1"><a class="reference internal" href="NearestNeighbors.html">12. Nearest Neighbours methods <a class="anchor" id="nearestneighbours"></a></a></li>
<li class="toctree-l1"><a class="reference internal" href="SupportVectorMachine.html">13. Support Vector Machine (SVM) <a class="anchor" id="supportvectormachine"></a></a></li>
<li class="toctree-l1"><a class="reference internal" href="DecisionTrees.html">14. Decision trees and forests <a class="anchor" id="dtaforests"></a></a></li>
<li class="toctree-l1"><a class="reference internal" href="Regression.html">15. Regression and regularisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="NeuralNetworks.html">16. Artificial Neural Networks (ANN)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">17. Model learning strategies</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://notebooks.csc.fi/#/blueprint/d1fe6e08032e4c17a0f9e0e222414598/hub/user-redirect/git-pull?repo=https%3A//github.com/pevalisuo/AML.git&urlpath=tree/AML.git/book/Learning_model_parameters.ipynb&branch=master" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on JupyterHub"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="JupyterHub logo" src="_static/images/logo_jupyterhub.svg">
  </span>
<span class="btn__text-container">JupyterHub</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Learning_model_parameters.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Model learning strategies</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">17. Model learning strategies</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimization-of-the-error-function">17.1. Minimization of the Error function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-functions">17.2. Loss functions</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent">18. Gradient descent</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-gradient-descent-sgd">19. Stochastic gradient descent (SGD)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-partial-derivatives-needed-in-the-update-step">19.1. The partial derivatives needed in the update step</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-in-neural-networks">20. Learning in Neural Networks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-backpropagation-algorithm">20.1. The backpropagation algorithm</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#mini-batch">21. Mini-batch</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#example">22. Example</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-learning">22.1. Partial learning</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="model-learning-strategies">
<h1><span class="section-number">17. </span>Model learning strategies<a class="headerlink" href="#model-learning-strategies" title="Link to this heading">#</a></h1>
<p>The model optimisation requires</p>
<ol class="arabic simple">
<li><p>Method to evaluate the quality of a current model</p></li>
<li><p>A strategy for improving the model one step better</p></li>
</ol>
<p>Usually the model quality is evaluated by means of a Loss function and optional regularization term. The loss function shows how large error the model makes in prediction and the regularization term shows how complex the model is. The purpose of the optimization is to minimize both the prediction error and complexity of the model. Too complex model may cause overfitting, and therefore regularization is important.</p>
<p>Let <span class="math notranslate nohighlight">\(f()\)</span> be the scoring function which estimates the prediction <span class="math notranslate nohighlight">\(\hat y = f(x_i)\)</span>.</p>
<section id="minimization-of-the-error-function">
<h2><span class="section-number">17.1. </span>Minimization of the Error function<a class="headerlink" href="#minimization-of-the-error-function" title="Link to this heading">#</a></h2>
<p>The general strategy of the model optimisation is then to minimize the regularized training error,  <span class="math notranslate nohighlight">\(E\)</span>, which includes both prediction losses and reqularization term:</p>
<div class="math notranslate nohighlight">
\[
 E(w,b) = \frac{1}{n} \sum_{i=1}^N L\left( y_i, f(x_i) \right) + \alpha R(w)
\]</div>
<p>The regularization coefficient, <span class="math notranslate nohighlight">\(\alpha\)</span>, determines the tradeoff between model complexity and prediction accuracy.</p>
</section>
<section id="loss-functions">
<h2><span class="section-number">17.2. </span>Loss functions<a class="headerlink" href="#loss-functions" title="Link to this heading">#</a></h2>
<p>The model leads to different models depending on the loss functions selected and the regularization used. For example the minimization of the error function using <span class="math notranslate nohighlight">\(L_2\)</span> norm without regularization leads to OLS regression model, and with <span class="math notranslate nohighlight">\(L_2\)</span> regularization to ridge regression model.</p>
<p>For example, consider the following two dimensional regression problem:</p>
<div class="math notranslate nohighlight">
\[\hat y = w_1 x_1 + w_2  x_2 + b \]</div>
<p>The <span class="math notranslate nohighlight">\(L_2\)</span> loss function for the problem is:
$<span class="math notranslate nohighlight">\(L=(y-\hat y)^2 = (y - f(x))^2\)</span>$</p>
<p>Without regularization, the loss function can be directly used as error function, and it’s minimization leads to
Linear regression model. By adding <span class="math notranslate nohighlight">\(L_2\)</span> regularization, it leads to ridge regression model, which can both be solved with closed form solutions, but the model can also be found by iterative optimization.</p>
<p>The optimization methods, such as gradient descent method, can be applied indentically to many other loss functions than <span class="math notranslate nohighlight">\(L_2\)</span>-norm, providing and interesting general framework for developing many kinds of machine learning models. The model type will be different when it is optimised with different loss functions and different regularization terms are used.</p>
<p>The most often used loss functions and their relation to the model types are shown in the following table:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Name</p></th>
<th class="head text-left"><p>Loss function</p></th>
<th class="head text-left"><p>Type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Hinge loss</p></td>
<td class="text-left"><p>$<span class="math notranslate nohighlight">\(L(y_i, f(x_i) = max\left(0,1-y_i f(x_i)\right)\)</span>$</p></td>
<td class="text-left"><p>Support vector Classification</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Perceptron</p></td>
<td class="text-left"><p>$<span class="math notranslate nohighlight">\(L(y_i, f(x_i) = max\left(0,-y_i f(x_i)\right)\)</span>$</p></td>
<td class="text-left"><p>ANN</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Huber</p></td>
<td class="text-left"><p>$$L(y_i, f(x_i) = \epsilon</p></td>
<td class="text-left"><p>y_i-f(x_i)</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Modified Huber</p></td>
<td class="text-left"><p>$<span class="math notranslate nohighlight">\(L(y_i, f(x_i) = max\left(0,1-y_i f(x_i)\right)^2, ...\)</span>$</p></td>
<td class="text-left"><p>Classification</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Log</p></td>
<td class="text-left"><p>$<span class="math notranslate nohighlight">\(L(y_i, f(x_i) = log\left(1+e^{-y_i f(x_i)}\right)\)</span>$</p></td>
<td class="text-left"><p>Logistic regression</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><span class="math notranslate nohighlight">\(L_2\)</span></p></td>
<td class="text-left"><p>$<span class="math notranslate nohighlight">\(L(y_i, f(x_i) = \frac{1}{2} \left(y_i,-f(x_i)\right)^2\)</span>$</p></td>
<td class="text-left"><p>OLS, Ridge or Lasso</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Epsilon insensitive</p></td>
<td class="text-left"><p>$$L(y_i, f(x_i) = max\left(0,</p></td>
<td class="text-left"><p>y_i,-f(x_i)</p></td>
</tr>
</tbody>
</table>
</div>
<p>This means that one common optimisation framework can implement many common machine learning solutions which are often trained with specialized program code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">fixed</span><span class="p">,</span> <span class="n">interact_manual</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hinge</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">yh</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span>  <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="o">*</span><span class="n">yh</span><span class="p">)</span>
<span class="n">perceptron</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">yh</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="n">y</span><span class="o">*</span><span class="n">yh</span><span class="p">)</span>
<span class="n">huber</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">yh</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">e</span><span class="o">=</span><span class="mf">1.35</span><span class="p">:</span> <span class="n">e</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">yh</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="n">e</span><span class="o">**</span><span class="mi">2</span>
<span class="n">mhuber</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">yh</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span>  <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="o">*</span><span class="n">yh</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">yh</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">y</span><span class="o">*</span><span class="n">yh</span><span class="p">))</span>
<span class="n">l2norm</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">yh</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="mi">1</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">yh</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="n">l1norm</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">yh</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">yh</span><span class="p">)</span>
<span class="n">epsilon</span><span class="o">=</span> <span class="k">lambda</span> <span class="n">yh</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">e</span><span class="o">=</span><span class="mf">1.35</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">yh</span><span class="p">)</span><span class="o">-</span><span class="n">e</span><span class="p">)</span>

<span class="n">lossfunctions</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;C: Hinge&#39;</span><span class="p">:</span> <span class="n">hinge</span><span class="p">,</span> 
               <span class="s1">&#39;C: Perceptron&#39;</span> <span class="p">:</span> <span class="n">perceptron</span><span class="p">,</span> 
               <span class="s1">&#39;C: Modified Huber&#39;</span><span class="p">:</span> <span class="n">mhuber</span><span class="p">,</span>
               <span class="s1">&#39;C: Logistic&#39;</span> <span class="p">:</span> <span class="n">logreg</span><span class="p">,</span> 
               <span class="s1">&#39;R: Huber&#39;</span><span class="p">:</span> <span class="n">huber</span><span class="p">,</span> 
               <span class="s1">&#39;R: L2&#39;</span> <span class="p">:</span> <span class="n">l2norm</span><span class="p">,</span> 
               <span class="s1">&#39;R: L1&#39;</span> <span class="p">:</span> <span class="n">l1norm</span><span class="p">,</span> 
               <span class="s1">&#39;R: Epsilon insensitive&#39;</span> <span class="p">:</span> <span class="n">epsilon</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yh</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;L2&#39;</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">yh</span><span class="p">,</span> <span class="n">lossfunctions</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">lossfunctions</span><span class="p">[</span><span class="n">loss</span><span class="p">](</span><span class="n">yh</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">yh</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
    
<span class="n">interact</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">loss</span><span class="o">=</span><span class="n">lossfunctions</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "b6eb3678b0cd4e5e848a977e7e181e10"}</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.test(y=0, loss=&#39;L2&#39;)&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">=</span><span class="mi">1</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">axc</span><span class="p">,</span> <span class="n">axr</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">lfname</span> <span class="ow">in</span> <span class="n">lossfunctions</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">lfname</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;C&#39;</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axc</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">=</span><span class="n">axr</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">lossfunctions</span><span class="p">[</span><span class="n">lfname</span><span class="p">](</span><span class="n">yh</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">yh</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lfname</span><span class="p">)</span>
<span class="n">axc</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axr</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axc</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axr</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axc</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\hat y$&#39;</span><span class="p">)</span>
<span class="n">axr</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\hat y$&#39;</span><span class="p">)</span>
<span class="n">axc</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Loss functions for classification&#39;</span><span class="p">)</span>
<span class="n">axr</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Loss functions for regression&#39;</span><span class="p">)</span>
<span class="n">axc</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">],</span> <span class="s1">&#39;k:&#39;</span><span class="p">)</span>
<span class="n">axr</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">],</span> <span class="s1">&#39;k:&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D at 0x789bd01d8e10&gt;]
</pre></div>
</div>
<img alt="_images/88b02db01855f87768799f8e380aab704b9d74456bf6fde99557a231cc750094.png" src="_images/88b02db01855f87768799f8e380aab704b9d74456bf6fde99557a231cc750094.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="gradient-descent">
<h1><span class="section-number">18. </span>Gradient descent<a class="headerlink" href="#gradient-descent" title="Link to this heading">#</a></h1>
<p>The Gradient descent is a common optimisation strategy, where the minimal value of the scoring function <span class="math notranslate nohighlight">\(f(x)\)</span> is found by calculating the partial derivatives of <span class="math notranslate nohighlight">\(f()\)</span> by all of its parameters, and updating the model parameters towards the negative gradient.</p>
<p>Gradient descent calculates the gradient using all samples in the training set, which may be rather resource intensive.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="stochastic-gradient-descent-sgd">
<h1><span class="section-number">19. </span>Stochastic gradient descent (SGD)<a class="headerlink" href="#stochastic-gradient-descent-sgd" title="Link to this heading">#</a></h1>
<p>The utilize computational resources more efficiently, the gradient descent method can be modified so that it calculates the gradient and updates the model for every individual sample in the training set. This method provides only noisy estimate of the gradient, and the models is not advancing towards the minimum as directly as the gradient decent, but it usually converges faster than Gradient Descent. Due to this partly stochastic behaviour, this method is called as Stochastic Gradient Descent (SGD).</p>
<p>In SGD the learning of the model is made in the following steps:</p>
<ol class="arabic simple">
<li><p>The training data is shuffled in random order</p></li>
<li><p>Initial values for models parameters, e.g. <span class="math notranslate nohighlight">\(w_1, w_2\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are set. They can be selected randomly or using some educated guess.</p></li>
<li><p>The training data is went through in random order performing the following actions for each sample</p></li>
<li><p>Calculate the loss <span class="math notranslate nohighlight">\(L(w,b)\)</span> of the prediction</p></li>
<li><p>Calculate the complecity <span class="math notranslate nohighlight">\(R(w,b)\)</span> of the prediction</p></li>
<li><p>Update the parameters using the partial derivative of the error function by each model parameter <span class="math notranslate nohighlight">\((w,b)\)</span></p></li>
<li><p>When all samples are went through, reshuffle the data and run the next iteration. If the loss is below a threshold, stop the process and return the trained model</p></li>
</ol>
<section id="the-partial-derivatives-needed-in-the-update-step">
<h2><span class="section-number">19.1. </span>The partial derivatives needed in the update step<a class="headerlink" href="#the-partial-derivatives-needed-in-the-update-step" title="Link to this heading">#</a></h2>
<p>The model parameters are updated using the partial derivatives. If the loss function is the L2 norm, and the learning rate <span class="math notranslate nohighlight">\(\eta \in ]0,1[\)</span>, the new values for <span class="math notranslate nohighlight">\(w_1, w_2\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are calculated as follows:</p>
<div class="math notranslate nohighlight">
\[ w'_1 = w_1 - \eta \frac{\partial L}{\partial w_1} 
= w_1 - \eta \frac{\partial L}{\partial \hat y} 
\cdot \frac{\partial \hat y}{\partial w_1} 
= w_1 - \eta \left(2(\hat y -y) \cdot x_1 \right) \]</div>
<div class="math notranslate nohighlight">
\[ w'_2 = w_2 - \eta \frac{\partial L}{\partial w_2} 
= w_2 - \eta \frac{\partial L}{\partial \hat y} 
\cdot \frac{\partial \hat y}{\partial w_2} 
= w_2 - \eta \left(2(\hat y -y)\cdot x_2 \right) \]</div>
<div class="math notranslate nohighlight">
\[ b' = b - \eta \frac{\partial L}{\partial b}
\cdot \frac{\partial \hat y}{\partial b} 
= b - \eta \left(2(\hat y -y)\cdot 1 \right) \]</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="learning-in-neural-networks">
<h1><span class="section-number">20. </span>Learning in Neural Networks<a class="headerlink" href="#learning-in-neural-networks" title="Link to this heading">#</a></h1>
<section id="the-backpropagation-algorithm">
<h2><span class="section-number">20.1. </span>The backpropagation algorithm<a class="headerlink" href="#the-backpropagation-algorithm" title="Link to this heading">#</a></h2>
<p>When using Stochastic Gradient Descent (<strong>SGD</strong>) training,  the weights, <span class="math notranslate nohighlight">\(w_i\)</span>, are updated towards the gradient (multidimensional derivative) or the loss function.
$<span class="math notranslate nohighlight">\(
    w \leftarrow w - \eta \left(\alpha \frac{\partial R(w)}{\partial w} + \frac{\partial L(w)}{\partial w}\right),
\)</span>$</p>
<p>where <span class="math notranslate nohighlight">\(\eta\)</span> is the learning rate, <span class="math notranslate nohighlight">\(\alpha\)</span> is the regularization term (L2 penalty for exessive model complexity), <span class="math notranslate nohighlight">\(R\)</span> is a function related to model complexity and <span class="math notranslate nohighlight">\(L\)</span> is a loss function. The weights of the model are simply updated to the direction where the model loss is reduced and model complexity is reduced.</p>
<p>Let us use the following perceptron as an example:
<img alt="Perceptron" src="_images/perceptron_sgd.svg" /></p>
<ul class="simple">
<li><p>First the network predicts the output <span class="math notranslate nohighlight">\(\hat{y} = f(x)\)</span> using the current weights <span class="math notranslate nohighlight">\(w\)</span>.</p></li>
<li><p>This prediction is perhaps not accurate but has a prediction error <span class="math notranslate nohighlight">\(y-\hat y\)</span>.</p></li>
<li><p>To make the network better, each coefficient <span class="math notranslate nohighlight">\(w\)</span> will be modified to make the error smaller. To calculate the direction and magnitude of change, the partial derivative of the output by the specific weight is calculated</p></li>
</ul>
<p>To update weight <span class="math notranslate nohighlight">\(w_1\)</span>, we’ll calculate <span class="math notranslate nohighlight">\(\frac{\partial L}{\partial w_1}\)</span>. The chain rule can be used for the calculation. For simplicity, it is assumed that the regularization is not being used.</p>
<p><span class="math notranslate nohighlight">\( S= \bf{w} \cdot \bf{x}\)</span></p>
<p>Sigmoid:  <span class="math notranslate nohighlight">\(\partial a(x) / \partial x = x(1-x)\)</span>
$<span class="math notranslate nohighlight">\(
   \frac{\partial L}{\partial w_1} 
    = \frac{\partial L}{\partial \hat y} \cdot \frac{\partial \hat y}{\partial S} \cdot \frac{\partial S}{\partial w_1}
    = \left(2\cdot (y-\hat y)\right) \cdot \left( S(1-S) \right) \cdot \left( x_1 \right)
\)</span>$</p>
<p>Relu: <span class="math notranslate nohighlight">\(\partial a(x) / \partial x = 1\)</span> (or 0 when <span class="math notranslate nohighlight">\(x \leq 0\)</span>
$<span class="math notranslate nohighlight">\(
   \frac{\partial L}{\partial w_1} 
    = \frac{\partial L}{\partial \hat y} \cdot \frac{\partial \hat y}{\partial S} \cdot \frac{\partial S}{\partial w_1}
    = \left(2\cdot (y-\hat y)\right) \cdot \left( 1 \right) \cdot \left( x_1 \right) = 2 (y-\hat y) x_1
\)</span>$</p>
<p>To update the perceptron using ReLU towards negative gradient for a step <span class="math notranslate nohighlight">\(\eta\)</span> requires that <span class="math notranslate nohighlight">\(w_1\)</span> will be updated as follows:</p>
<div class="math notranslate nohighlight">
\[
    w_1' = w_1 - \eta \cdot 2 (y-\hat y) x_1
\]</div>
<p>If S is negative for a neuron using ReLU, the output and the derivative will be zero, and the neuron is not updated in this run.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="mini-batch">
<h1><span class="section-number">21. </span>Mini-batch<a class="headerlink" href="#mini-batch" title="Link to this heading">#</a></h1>
<p>A mini-batch approach is similar than SGD, but instead of calculating the gradient from only one sample at the time, the mini-batch approach is to calculate the gradient from a small batch of samples at the time.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="example">
<h1><span class="section-number">22. </span>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">snippets</span> <span class="kn">import</span> <span class="n">plotDB</span><span class="p">,</span> <span class="n">DisplaySupportVectors</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">boston</span><span class="o">=</span><span class="n">load_boston</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ImportError</span><span class="g g-Whitespace">                               </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="n">line</span> <span class="mi">11</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="kn">from</span> <span class="nn">snippets</span> <span class="kn">import</span> <span class="n">plotDB</span><span class="p">,</span> <span class="n">DisplaySupportVectors</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDRegressor</span>
<span class="ne">---&gt; </span><span class="mi">11</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> <span class="n">boston</span><span class="o">=</span><span class="n">load_boston</span><span class="p">();</span>

<span class="nn">File ~/miniforge3/envs/octave/lib/python3.11/site-packages/sklearn/datasets/__init__.py:157,</span> in <span class="ni">__getattr__</span><span class="nt">(name)</span>
<span class="g g-Whitespace">    </span><span class="mi">108</span> <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;load_boston&quot;</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">109</span>     <span class="n">msg</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">dedent</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">110</span><span class="s2">         `load_boston` has been removed from scikit-learn since version 1.2.</span>
<span class="g g-Whitespace">    </span><span class="mi">111</span><span class="s2"> </span>
<span class="s2">   (...)</span>
<span class="g g-Whitespace">    </span><span class="mi">155</span><span class="s2">         &lt;https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air&gt;</span>
<span class="g g-Whitespace">    </span><span class="mi">156</span><span class="s2">         &quot;&quot;&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">157</span>     <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">158</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">159</span>     <span class="k">return</span> <span class="nb">globals</span><span class="p">()[</span><span class="n">name</span><span class="p">]</span>

<span class="ne">ImportError</span>: 
<span class="err">`</span><span class="n">load_boston</span><span class="err">`</span> <span class="n">has</span> <span class="n">been</span> <span class="n">removed</span> <span class="kn">from</span> <span class="nn">scikit</span><span class="o">-</span><span class="n">learn</span> <span class="n">since</span> <span class="n">version</span> <span class="mf">1.2</span><span class="o">.</span>

<span class="n">The</span> <span class="n">Boston</span> <span class="n">housing</span> <span class="n">prices</span> <span class="n">dataset</span> <span class="n">has</span> <span class="n">an</span> <span class="n">ethical</span> <span class="n">problem</span><span class="p">:</span> <span class="k">as</span>
<span class="n">investigated</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">the</span> <span class="n">authors</span> <span class="n">of</span> <span class="n">this</span> <span class="n">dataset</span> <span class="n">engineered</span> <span class="n">a</span>
<span class="n">non</span><span class="o">-</span><span class="n">invertible</span> <span class="n">variable</span> <span class="s2">&quot;B&quot;</span> <span class="n">assuming</span> <span class="n">that</span> <span class="n">racial</span> <span class="bp">self</span><span class="o">-</span><span class="n">segregation</span> <span class="n">had</span> <span class="n">a</span>
<span class="n">positive</span> <span class="n">impact</span> <span class="n">on</span> <span class="n">house</span> <span class="n">prices</span> <span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span> <span class="n">Furthermore</span> <span class="n">the</span> <span class="n">goal</span> <span class="n">of</span> <span class="n">the</span>
<span class="n">research</span> <span class="n">that</span> <span class="n">led</span> <span class="n">to</span> <span class="n">the</span> <span class="n">creation</span> <span class="n">of</span> <span class="n">this</span> <span class="n">dataset</span> <span class="n">was</span> <span class="n">to</span> <span class="n">study</span> <span class="n">the</span>
<span class="n">impact</span> <span class="n">of</span> <span class="n">air</span> <span class="n">quality</span> <span class="n">but</span> <span class="n">it</span> <span class="n">did</span> <span class="ow">not</span> <span class="n">give</span> <span class="n">adequate</span> <span class="n">demonstration</span> <span class="n">of</span> <span class="n">the</span>
<span class="n">validity</span> <span class="n">of</span> <span class="n">this</span> <span class="n">assumption</span><span class="o">.</span>

<span class="n">The</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span> <span class="n">maintainers</span> <span class="n">therefore</span> <span class="n">strongly</span> <span class="n">discourage</span> <span class="n">the</span> <span class="n">use</span> <span class="n">of</span>
<span class="n">this</span> <span class="n">dataset</span> <span class="n">unless</span> <span class="n">the</span> <span class="n">purpose</span> <span class="n">of</span> <span class="n">the</span> <span class="n">code</span> <span class="ow">is</span> <span class="n">to</span> <span class="n">study</span> <span class="ow">and</span> <span class="n">educate</span>
<span class="n">about</span> <span class="n">ethical</span> <span class="n">issues</span> <span class="ow">in</span> <span class="n">data</span> <span class="n">science</span> <span class="ow">and</span> <span class="n">machine</span> <span class="n">learning</span><span class="o">.</span>

<span class="n">In</span> <span class="n">this</span> <span class="n">special</span> <span class="n">case</span><span class="p">,</span> <span class="n">you</span> <span class="n">can</span> <span class="n">fetch</span> <span class="n">the</span> <span class="n">dataset</span> <span class="kn">from</span> <span class="nn">the</span> <span class="n">original</span>
<span class="ne">source</span>::

    <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

    <span class="n">data_url</span> <span class="o">=</span> <span class="s2">&quot;http://lib.stat.cmu.edu/datasets/boston&quot;</span>
    <span class="n">raw_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_url</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;\s+&quot;</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="mi">22</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">raw_df</span><span class="o">.</span><span class="n">values</span><span class="p">[::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:],</span> <span class="n">raw_df</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]])</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">raw_df</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>

<span class="n">Alternative</span> <span class="n">datasets</span> <span class="n">include</span> <span class="n">the</span> <span class="n">California</span> <span class="n">housing</span> <span class="n">dataset</span> <span class="ow">and</span> <span class="n">the</span>
<span class="n">Ames</span> <span class="n">housing</span> <span class="n">dataset</span><span class="o">.</span> <span class="n">You</span> <span class="n">can</span> <span class="n">load</span> <span class="n">the</span> <span class="n">datasets</span> <span class="k">as</span> <span class="n">follows</span><span class="p">::</span>

    <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_california_housing</span>
    <span class="n">housing</span> <span class="o">=</span> <span class="n">fetch_california_housing</span><span class="p">()</span>

<span class="k">for</span> <span class="n">the</span> <span class="n">California</span> <span class="n">housing</span> <span class="n">dataset</span> <span class="ow">and</span><span class="p">::</span>

    <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_openml</span>
    <span class="n">housing</span> <span class="o">=</span> <span class="n">fetch_openml</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;house_prices&quot;</span><span class="p">,</span> <span class="n">as_frame</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">for</span> <span class="n">the</span> <span class="n">Ames</span> <span class="n">housing</span> <span class="n">dataset</span><span class="o">.</span>

<span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">M</span> <span class="n">Carlisle</span><span class="o">.</span>
<span class="s2">&quot;Racist data destruction?&quot;</span>
<span class="o">&lt;</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">medium</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="nd">@docintangible</span><span class="o">/</span><span class="n">racist</span><span class="o">-</span><span class="n">data</span><span class="o">-</span><span class="n">destruction</span><span class="o">-</span><span class="mf">113e3</span><span class="n">eff54a8</span><span class="o">&gt;</span>

<span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="n">Harrison</span> <span class="n">Jr</span><span class="p">,</span> <span class="n">David</span><span class="p">,</span> <span class="ow">and</span> <span class="n">Daniel</span> <span class="n">L</span><span class="o">.</span> <span class="n">Rubinfeld</span><span class="o">.</span>
<span class="s2">&quot;Hedonic housing prices and the demand for clean air.&quot;</span>
<span class="n">Journal</span> <span class="n">of</span> <span class="n">environmental</span> <span class="n">economics</span> <span class="ow">and</span> <span class="n">management</span> <span class="mf">5.1</span> <span class="p">(</span><span class="mi">1978</span><span class="p">):</span> <span class="mi">81</span><span class="o">-</span><span class="mf">102.</span>
<span class="o">&lt;</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">researchgate</span><span class="o">.</span><span class="n">net</span><span class="o">/</span><span class="n">publication</span><span class="o">/</span><span class="mi">4974606</span><span class="n">_Hedonic_housing_prices_and_the_demand_for_clean_air</span><span class="o">&gt;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

<span class="c1"># Always scale the input. The most convenient way is to use a pipeline.</span>
<span class="c1"># Default values for the classifier are pretty good, but you can try to change them </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span>
                    <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;hinge&#39;</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;L2&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">yh_train</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">yh_test</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1">#plt.scatter(X[:,0], X[:,1], c=y, cmap=&#39;rainbow&#39;)</span>
<span class="c1">#plt.xlabel(&#39;Feature 1&#39;)</span>
<span class="c1">#plt.ylabel(&#39;Feature 2&#39;)</span>
<span class="n">plotDB</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy training..&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="n">yh_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy test......&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">yh_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy training.. 0.9413333333333334
Accuracy test...... 0.92
</pre></div>
</div>
<img alt="_images/b424d17f9ff813ea91e005efea0392f12a328822ce2f5f7cdbbb4804dc5d1ebb.png" src="_images/b424d17f9ff813ea91e005efea0392f12a328822ce2f5f7cdbbb4804dc5d1ebb.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
<span class="n">y</span><span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span>
                    <span class="n">SGDRegressor</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;squared_error&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>
<span class="o">%</span><span class="k">time</span> model.fit(X_train, y_train)
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of interations needed:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">n_iter_</span><span class="p">)</span>

<span class="c1"># Cross_val_score and score are coefficient of determinations, R^2</span>
<span class="n">RsquaredTR</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">RSquaredTE</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">RSquaredTA</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">line_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;red&quot;</span><span class="p">})</span>
<span class="n">RsquaredCV</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;True price&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Predicted price&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Comparison of two-feature model, $R^2$=</span><span class="si">%3.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">RsquaredCV</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training score.....&quot;</span><span class="p">,</span> <span class="n">RsquaredTR</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CV score...........&quot;</span><span class="p">,</span> <span class="n">RsquaredCV</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing score......&quot;</span><span class="p">,</span> <span class="n">RSquaredTE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All samples score..&quot;</span><span class="p">,</span> <span class="n">RSquaredTA</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 2.24 ms, sys: 804 µs, total: 3.05 ms
Wall time: 2.49 ms
Number of interations needed: 19

Training score..... 0.7131419729477999
CV score........... 0.4629178151630411
Testing score...... 0.7383414651344274
All samples score.. 0.7189004574726183
</pre></div>
</div>
<img alt="_images/01280c5aee314f93890b40c09c79cfdcc465127f8666e01fa383c5c4c9a74eb4.png" src="_images/01280c5aee314f93890b40c09c79cfdcc465127f8666e01fa383c5c4c9a74eb4.png" />
</div>
</div>
<section id="partial-learning">
<h2><span class="section-number">22.1. </span>Partial learning<a class="headerlink" href="#partial-learning" title="Link to this heading">#</a></h2>
<p>The SGD modules can be also trained step by step</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Step by step</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">SGDRegressor</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;squared_error&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;L2&#39;</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_tr</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_te</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">scores_tr</span><span class="o">=</span><span class="p">[]</span>
<span class="n">scores_te</span><span class="o">=</span><span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1700</span><span class="p">):</span>
    <span class="n">reg</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">scores_tr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
    <span class="n">scores_te</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_te</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_tr</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_te</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">scores_tr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">scores_te</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testing&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1699 0.7342712663890836 0.755665784954104
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x7f33a589acd0&gt;
</pre></div>
</div>
<img alt="_images/5da2c061c1535562b2b8a372fa329ad21a809752cf7d82cec94c16ecffac709e.png" src="_images/5da2c061c1535562b2b8a372fa329ad21a809752cf7d82cec94c16ecffac709e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">12</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;RM&#39;, &#39;PTRATIO&#39;, &#39;LSTAT&#39;], dtype=&#39;&lt;U7&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;CRIM&#39;, &#39;ZN&#39;, &#39;INDUS&#39;, &#39;CHAS&#39;, &#39;NOX&#39;, &#39;RM&#39;, &#39;AGE&#39;, &#39;DIS&#39;, &#39;RAD&#39;,
       &#39;TAX&#39;, &#39;PTRATIO&#39;, &#39;B&#39;, &#39;LSTAT&#39;], dtype=&#39;&lt;U7&#39;)
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="NeuralNetworks.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">16. </span>Artificial Neural Networks (ANN)</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">17. Model learning strategies</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#minimization-of-the-error-function">17.1. Minimization of the Error function</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-functions">17.2. Loss functions</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent">18. Gradient descent</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-gradient-descent-sgd">19. Stochastic gradient descent (SGD)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-partial-derivatives-needed-in-the-update-step">19.1. The partial derivatives needed in the update step</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-in-neural-networks">20. Learning in Neural Networks</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-backpropagation-algorithm">20.1. The backpropagation algorithm</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#mini-batch">21. Mini-batch</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#example">22. Example</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-learning">22.1. Partial learning</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Petri Välisuo
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>