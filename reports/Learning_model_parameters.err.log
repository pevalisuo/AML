Traceback (most recent call last):
  File "/home/petri/miniforge3/envs/octave/lib/python3.11/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/home/petri/miniforge3/envs/octave/lib/python3.11/site-packages/nbclient/client.py", line 1305, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/petri/miniforge3/envs/octave/lib/python3.11/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/petri/miniforge3/envs/octave/lib/python3.11/asyncio/base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/petri/miniforge3/envs/octave/lib/python3.11/site-packages/nbclient/client.py", line 705, in async_execute
    await self.async_execute_cell(
  File "/home/petri/miniforge3/envs/octave/lib/python3.11/site-packages/nbclient/client.py", line 1058, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/petri/miniforge3/envs/octave/lib/python3.11/site-packages/nbclient/client.py", line 914, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import numpy as np
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn import datasets
from sklearn.metrics import accuracy_score, r2_score
from sklearn.model_selection import train_test_split
from snippets import plotDB, DisplaySupportVectors

from sklearn.linear_model import SGDRegressor
from sklearn.datasets import load_boston
from sklearn.model_selection import cross_val_score

boston=load_boston();
------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mImportError[0m                               Traceback (most recent call last)
Cell [0;32mIn[5], line 11[0m
[1;32m      8[0m [38;5;28;01mfrom[39;00m [38;5;21;01msnippets[39;00m [38;5;28;01mimport[39;00m plotDB, DisplaySupportVectors
[1;32m     10[0m [38;5;28;01mfrom[39;00m [38;5;21;01msklearn[39;00m[38;5;21;01m.[39;00m[38;5;21;01mlinear_model[39;00m [38;5;28;01mimport[39;00m SGDRegressor
[0;32m---> 11[0m [38;5;28;01mfrom[39;00m [38;5;21;01msklearn[39;00m[38;5;21;01m.[39;00m[38;5;21;01mdatasets[39;00m [38;5;28;01mimport[39;00m load_boston
[1;32m     12[0m [38;5;28;01mfrom[39;00m [38;5;21;01msklearn[39;00m[38;5;21;01m.[39;00m[38;5;21;01mmodel_selection[39;00m [38;5;28;01mimport[39;00m cross_val_score
[1;32m     14[0m boston[38;5;241m=[39mload_boston();

File [0;32m~/miniforge3/envs/octave/lib/python3.11/site-packages/sklearn/datasets/__init__.py:157[0m, in [0;36m__getattr__[0;34m(name)[0m
[1;32m    108[0m [38;5;28;01mif[39;00m name [38;5;241m==[39m [38;5;124m"[39m[38;5;124mload_boston[39m[38;5;124m"[39m:
[1;32m    109[0m     msg [38;5;241m=[39m textwrap[38;5;241m.[39mdedent([38;5;124m"""[39m
[1;32m    110[0m [38;5;124m        `load_boston` has been removed from scikit-learn since version 1.2.[39m
[1;32m    111[0m 
[0;32m   (...)[0m
[1;32m    155[0m [38;5;124m        <https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>[39m
[1;32m    156[0m [38;5;124m        [39m[38;5;124m"""[39m)
[0;32m--> 157[0m     [38;5;28;01mraise[39;00m [38;5;167;01mImportError[39;00m(msg)
[1;32m    158[0m [38;5;28;01mtry[39;00m:
[1;32m    159[0m     [38;5;28;01mreturn[39;00m [38;5;28mglobals[39m()[name]

[0;31mImportError[0m: 
`load_boston` has been removed from scikit-learn since version 1.2.

The Boston housing prices dataset has an ethical problem: as
investigated in [1], the authors of this dataset engineered a
non-invertible variable "B" assuming that racial self-segregation had a
positive impact on house prices [2]. Furthermore the goal of the
research that led to the creation of this dataset was to study the
impact of air quality but it did not give adequate demonstration of the
validity of this assumption.

The scikit-learn maintainers therefore strongly discourage the use of
this dataset unless the purpose of the code is to study and educate
about ethical issues in data science and machine learning.

In this special case, you can fetch the dataset from the original
source::

    import pandas as pd
    import numpy as np

    data_url = "http://lib.stat.cmu.edu/datasets/boston"
    raw_df = pd.read_csv(data_url, sep="\s+", skiprows=22, header=None)
    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
    target = raw_df.values[1::2, 2]

Alternative datasets include the California housing dataset and the
Ames housing dataset. You can load the datasets as follows::

    from sklearn.datasets import fetch_california_housing
    housing = fetch_california_housing()

for the California housing dataset and::

    from sklearn.datasets import fetch_openml
    housing = fetch_openml(name="house_prices", as_frame=True)

for the Ames housing dataset.

[1] M Carlisle.
"Racist data destruction?"
<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>

[2] Harrison Jr, David, and Daniel L. Rubinfeld.
"Hedonic housing prices and the demand for clean air."
Journal of environmental economics and management 5.1 (1978): 81-102.
<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>


